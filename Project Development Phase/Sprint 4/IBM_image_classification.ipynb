{"cells": [{"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 1, "outputs": [{"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='HaJV5PfQ3pclB58vpjjNM39n-V1FojdGcHPeTGjkWTwF',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'agesturebasedtoolforsterilebrowsi-donotdelete-pr-fu4hinhb0wo8v5'\nobject_key = 'Dataset.zip'\n\nstreaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip=zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\nfile_paths=unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# This library helps add support for large, multi-dimensional arrays and matrices\nimport numpy as np\n#open source used for both ML and DL for computation\nimport tensorflow as tf\n#it is a plain stack of layers\nfrom tensorflow.keras.models import Sequential \n#Dense layer is the regular deeply connected neural network layer\nfrom tensorflow.keras.layers import Dense,Flatten, Dropout\n#Faltten-used fot flattening the input or change the dimension, MaxPooling2D-for downsampling the image for Convolutional layer\nfrom tensorflow.keras.layers import Convolution2D,MaxPooling2D \n#Its used for different augmentation of the image \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#setting parameter for Image Data agumentation to the traing data\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n#Image Data agumentation to the testing data\ntest_datagen=ImageDataGenerator(rescale=1./255)", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='nfPfol8vLIEpEFv87J4Mt6DObJzRHfheN3_xeooXvdVi',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'imageclassification-donotdelete-pr-lhudywwwmjpnbo'\nobject_key = 'DATASET.zip'\n\nstreaming_body_3 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#performing data agumentation to train data\nx_train = train_datagen.flow_from_directory(r'/home/wsuser/work/Dataset/train',\n                                            target_size=(64, 64),\n                                            batch_size=3,\n                                            color_mode='grayscale',\n                                            class_mode='categorical')\n#performing data agumentation to test data\nx_test = test_datagen.flow_from_directory(r'/home/wsuser/work/Dataset/test',\n                                          target_size=(64, 64),\n                                          batch_size=3,\n                                          color_mode='grayscale',\n                                          class_mode='categorical') ", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Found 594 images belonging to 6 classes.\nFound 30 images belonging to 6 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(x_train.class_indices)#checking the number of classes", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Initializing the CNN\nmodel = Sequential()", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# First convolution layer and pooling\nmodel.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Second convolution layer and pooling\nmodel.add(Convolution2D(32, (3, 3), activation='relu'))\n# input_shape is going to be the pooled feature maps from the previous convolution layer\nmodel.add(MaxPooling2D(pool_size=(2,2)))", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Flattening the layers i.e. input layer\nmodel.add(Flatten())", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Adding a fully connected layer, i.e. Hidden Layer\nmodel.add(Dense(units=512 , activation='relu'))", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# softmax for categorical analysis, Output Layer\nmodel.add(Dense(units=6, activation='softmax')) ", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.summary()#summary of our model", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 62, 62, 32)        320       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 6272)              0         \n                                                                 \n dense (Dense)               (None, 512)               3211776   \n                                                                 \n dense_1 (Dense)             (None, 6)                 3078      \n                                                                 \n=================================================================\nTotal params: 3,224,422\nTrainable params: 3,224,422\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Compiling the CNN\n# categorical_crossentropy for more than 2\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) ", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# It will generate packets of train and test data for training\nmodel.fit_generator(x_train,\n                    steps_per_epoch = 594/3 , \n                    epochs = 25, \n                    validation_data = x_test,\n                    validation_steps = 30/3 )", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "/tmp/wsuser/ipykernel_164/804983804.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(x_train,\n", "name": "stderr"}, {"output_type": "stream", "text": "Epoch 1/25\n198/198 [==============================] - 8s 38ms/step - loss: 1.2797 - accuracy: 0.4630 - val_loss: 0.6806 - val_accuracy: 0.7667\nEpoch 2/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.6322 - accuracy: 0.7542 - val_loss: 0.5509 - val_accuracy: 0.7667\nEpoch 3/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.4508 - accuracy: 0.8182 - val_loss: 0.3961 - val_accuracy: 0.9000\nEpoch 4/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.3104 - accuracy: 0.8788 - val_loss: 0.4336 - val_accuracy: 0.8333\nEpoch 5/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.2005 - accuracy: 0.9259 - val_loss: 0.2968 - val_accuracy: 0.9000\nEpoch 6/25\n198/198 [==============================] - 7s 36ms/step - loss: 0.1549 - accuracy: 0.9444 - val_loss: 0.2392 - val_accuracy: 0.9000\nEpoch 7/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.1026 - accuracy: 0.9697 - val_loss: 0.2657 - val_accuracy: 0.9333\nEpoch 8/25\n198/198 [==============================] - 7s 36ms/step - loss: 0.1363 - accuracy: 0.9444 - val_loss: 0.2448 - val_accuracy: 0.9333\nEpoch 9/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.1112 - accuracy: 0.9630 - val_loss: 0.5341 - val_accuracy: 0.8667\nEpoch 10/25\n198/198 [==============================] - 7s 36ms/step - loss: 0.0655 - accuracy: 0.9815 - val_loss: 0.2261 - val_accuracy: 0.9667\nEpoch 11/25\n198/198 [==============================] - 7s 36ms/step - loss: 0.0682 - accuracy: 0.9815 - val_loss: 0.4014 - val_accuracy: 0.9333\nEpoch 12/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0656 - accuracy: 0.9764 - val_loss: 0.2270 - val_accuracy: 0.9667\nEpoch 13/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0701 - accuracy: 0.9815 - val_loss: 0.3203 - val_accuracy: 0.9000\nEpoch 14/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0463 - accuracy: 0.9848 - val_loss: 0.2347 - val_accuracy: 0.9333\nEpoch 15/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0463 - accuracy: 0.9798 - val_loss: 0.2923 - val_accuracy: 0.9333\nEpoch 16/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0928 - accuracy: 0.9646 - val_loss: 0.3217 - val_accuracy: 0.8667\nEpoch 17/25\n198/198 [==============================] - 7s 38ms/step - loss: 0.0354 - accuracy: 0.9865 - val_loss: 0.1200 - val_accuracy: 0.9667\nEpoch 18/25\n198/198 [==============================] - 7s 36ms/step - loss: 0.0226 - accuracy: 0.9916 - val_loss: 0.1331 - val_accuracy: 0.9333\nEpoch 19/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0511 - accuracy: 0.9899 - val_loss: 0.1613 - val_accuracy: 0.9667\nEpoch 20/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0253 - accuracy: 0.9899 - val_loss: 0.0973 - val_accuracy: 0.9667\nEpoch 21/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.0146 - val_accuracy: 1.0000\nEpoch 22/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0765 - accuracy: 0.9781 - val_loss: 0.1500 - val_accuracy: 0.9667\nEpoch 23/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0252 - accuracy: 0.9899 - val_loss: 0.1546 - val_accuracy: 0.9667\nEpoch 24/25\n198/198 [==============================] - 7s 37ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.2190 - val_accuracy: 0.9333\nEpoch 25/25\n198/198 [==============================] - 7s 36ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9333\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "<keras.callbacks.History at 0x7f9370b9f730>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Save the model\nmodel.save('gesture.h5')", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf Gesture-based-Radiology-Images.tgz gesture.h5", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "gesture.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls -l", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "total 71172\r\ndrwxrwx--- 4 wsuser wscommon     4096 Nov 19 10:48 \u001b[0m\u001b[01;34mDataset\u001b[0m/\r\n-rw-rw---- 1 wsuser wscommon 34126272 Nov 19 11:06 Gesture-based-Radiology-Images.tgz\r\n-rw-rw---- 1 wsuser wscommon 38740208 Nov 19 11:05 gesture.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model_json = model.to_json()\nwith open(\"model-bw.json\", \"w\") as json_file:\n    json_file.write(model_json)", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!pip install ibm_watson_machine_learning", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: ibm_watson_machine_learning in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.257)\nRequirement already satisfied: ibm-cos-sdk==2.11.* in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2.11.0)\nRequirement already satisfied: pandas<1.5.0,>=0.24.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (1.3.4)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2022.9.24)\nRequirement already satisfied: importlib-metadata in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (4.8.2)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (2.26.0)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (0.8.9)\nRequirement already satisfied: packaging in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (21.3)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (0.3.3)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_watson_machine_learning) (1.26.7)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.11.0)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (0.10.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.11.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk-core==2.11.0->ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas<1.5.0,>=0.24.2->ibm_watson_machine_learning) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas<1.5.0,>=0.24.2->ibm_watson_machine_learning) (1.20.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->ibm-cos-sdk-core==2.11.0->ibm-cos-sdk==2.11.*->ibm_watson_machine_learning) (1.15.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->ibm_watson_machine_learning) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->ibm_watson_machine_learning) (2.0.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from importlib-metadata->ibm_watson_machine_learning) (3.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->ibm_watson_machine_learning) (3.0.4)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials={\n    \"url\":\"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\":\"pqJtEWD8mZ7Wj_oidWxRffYfVHVCMgt6PLSlbNNyI23S\"\n}\n\nclient=APIClient(wml_credentials)", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def guid_space_name(client,space_name):\n    space=client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity']['name']==space_name)['metadata']['id'])", "execution_count": 28, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid=guid_space_name(client,'imageclassification')\nprint(\"Space UID \"+space_uid)", "execution_count": 29, "outputs": [{"output_type": "stream", "text": "Space UID 8af19536-8aca-437f-8687-5f5cc6c53e9b\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 30, "outputs": [{"output_type": "execute_result", "execution_count": 30, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": 31, "outputs": [{"output_type": "stream", "text": "-----------------------------  ------------------------------------  ----\nNAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nautoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\nruntime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nautoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\npytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\ndefault_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nruntime-22.2-py3.10-xc         5e8cddff-db4a-5a6a-b8aa-2d4af9864dab  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import tensorflow as tf\ntf.__version__", "execution_count": 32, "outputs": [{"output_type": "execute_result", "execution_count": 32, "data": {"text/plain": "'2.7.2'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import keras as ks\nks.__version__", "execution_count": 33, "outputs": [{"output_type": "execute_result", "execution_count": 33, "data": {"text/plain": "'2.7.0'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_rt22.1-py3.9\")\nsoftware_spec_uid", "execution_count": 45, "outputs": [{"output_type": "execute_result", "execution_count": 45, "data": {"text/plain": "'acd9c798-6974-5d2f-a657-ce06e986df4d'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details=client.repository.store_model(model='Gesture-based-Radiology-Images.tgz',meta_props={\n    client.repository.ModelMetaNames.NAME:'CNN',\n    client.repository.ModelMetaNames.TYPE:\"tensorflow_2.7\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid\n})\nmodel_id = client.repository.get_model_id(model_details)\nmodel_id", "execution_count": 48, "outputs": [{"output_type": "execute_result", "execution_count": 48, "data": {"text/plain": "'0df93fe9-05e3-4393-b782-6ea4ad48051f'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id,'my_model.tar.gz')", "execution_count": 49, "outputs": [{"output_type": "stream", "text": "File with name: 'my_model.tar.gz' already exists.\n", "name": "stderr"}, {"output_type": "error", "ename": "WMLClientError", "evalue": "File with name: 'my_model.tar.gz' already exists.", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/2096161494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'my_model.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ibm_watson_machine_learning/repository.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, artifact_uid, filename, rev_uid, format)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_uid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_uid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'function'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_uid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ibm_watson_machine_learning/models.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, model_uid, filename, rev_uid, format)\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \"\"\"\n\u001b[1;32m   1804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'File with name: \\'{}\\' already exists.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrev_uid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICP_30\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLOUD_PLATFORM_SPACES\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICP_35\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICP_40\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICP_45\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mWMLClientError\u001b[0m: File with name: 'my_model.tar.gz' already exists."]}]}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 53, "outputs": [{"output_type": "execute_result", "execution_count": 53, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}